{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "#fix random seed for reproducibility\n",
    "np.random.seed(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass   education   education-num       marital-status  \\\n",
      "0   39          State-gov   Bachelors              13        Never-married   \n",
      "1   50   Self-emp-not-inc   Bachelors              13   Married-civ-spouse   \n",
      "2   38            Private     HS-grad               9             Divorced   \n",
      "\n",
      "           occupation    relationship    race    sex   capital-gain  \\\n",
      "0        Adm-clerical   Not-in-family   White   Male           2174   \n",
      "1     Exec-managerial         Husband   White   Male              0   \n",
      "2   Handlers-cleaners   Not-in-family   White   Male              0   \n",
      "\n",
      "    capital-loss   hours-per-week  native-country  income  \n",
      "0              0               40   United-States   <=50K  \n",
      "1              0               13   United-States   <=50K  \n",
      "2              0               40   United-States   <=50K  \n"
     ]
    }
   ],
   "source": [
    "#import data set\n",
    "url = \"Adult_Census_Income_Binary_Classification_dataset.csv\"\n",
    "#read dataset to pandas dataframe\n",
    "dataset = pd.read_csv(url)\n",
    "print(dataset[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age          workclass   education   education-num       marital-status  \\\n",
      "0   39          State-gov   Bachelors              13        Never-married   \n",
      "1   50   Self-emp-not-inc   Bachelors              13   Married-civ-spouse   \n",
      "2   38            Private     HS-grad               9             Divorced   \n",
      "\n",
      "           occupation    relationship    race    sex   capital-gain  \\\n",
      "0        Adm-clerical   Not-in-family   White   Male           2174   \n",
      "1     Exec-managerial         Husband   White   Male              0   \n",
      "2   Handlers-cleaners   Not-in-family   White   Male              0   \n",
      "\n",
      "    capital-loss   hours-per-week  native-country  income  \n",
      "0              0               40   United-States   <=50K  \n",
      "1              0               13   United-States   <=50K  \n",
      "2              0               40   United-States   <=50K  \n"
     ]
    }
   ],
   "source": [
    "#changing missing values to NaN\n",
    "newdf = dataset.replace(r'\\?', np.nan, regex=True)\n",
    "print(newdf[0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2399"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking number of rows has at least one missing value\n",
    "newdf.isnull().any(axis=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age          workclass      education   education-num  \\\n",
      "0    39          State-gov      Bachelors              13   \n",
      "1    50   Self-emp-not-inc      Bachelors              13   \n",
      "2    38            Private        HS-grad               9   \n",
      "3    53            Private           11th               7   \n",
      "4    28            Private      Bachelors              13   \n",
      "5    37            Private        Masters              14   \n",
      "6    49            Private            9th               5   \n",
      "7    52   Self-emp-not-inc        HS-grad               9   \n",
      "8    31            Private        Masters              14   \n",
      "9    42            Private      Bachelors              13   \n",
      "10   37            Private   Some-college              10   \n",
      "11   30          State-gov      Bachelors              13   \n",
      "12   23            Private      Bachelors              13   \n",
      "13   32            Private     Assoc-acdm              12   \n",
      "15   34            Private        7th-8th               4   \n",
      "16   25   Self-emp-not-inc        HS-grad               9   \n",
      "17   32            Private        HS-grad               9   \n",
      "18   38            Private           11th               7   \n",
      "19   43   Self-emp-not-inc        Masters              14   \n",
      "20   40            Private      Doctorate              16   \n",
      "21   54            Private        HS-grad               9   \n",
      "22   35        Federal-gov            9th               5   \n",
      "23   43            Private           11th               7   \n",
      "24   59            Private        HS-grad               9   \n",
      "25   56          Local-gov      Bachelors              13   \n",
      "26   19            Private        HS-grad               9   \n",
      "28   39            Private        HS-grad               9   \n",
      "29   49            Private        HS-grad               9   \n",
      "30   23          Local-gov     Assoc-acdm              12   \n",
      "31   20            Private   Some-college              10   \n",
      "\n",
      "            marital-status          occupation    relationship  \\\n",
      "0            Never-married        Adm-clerical   Not-in-family   \n",
      "1       Married-civ-spouse     Exec-managerial         Husband   \n",
      "2                 Divorced   Handlers-cleaners   Not-in-family   \n",
      "3       Married-civ-spouse   Handlers-cleaners         Husband   \n",
      "4       Married-civ-spouse      Prof-specialty            Wife   \n",
      "5       Married-civ-spouse     Exec-managerial            Wife   \n",
      "6    Married-spouse-absent       Other-service   Not-in-family   \n",
      "7       Married-civ-spouse     Exec-managerial         Husband   \n",
      "8            Never-married      Prof-specialty   Not-in-family   \n",
      "9       Married-civ-spouse     Exec-managerial         Husband   \n",
      "10      Married-civ-spouse     Exec-managerial         Husband   \n",
      "11      Married-civ-spouse      Prof-specialty         Husband   \n",
      "12           Never-married        Adm-clerical       Own-child   \n",
      "13           Never-married               Sales   Not-in-family   \n",
      "15      Married-civ-spouse    Transport-moving         Husband   \n",
      "16           Never-married     Farming-fishing       Own-child   \n",
      "17           Never-married   Machine-op-inspct       Unmarried   \n",
      "18      Married-civ-spouse               Sales         Husband   \n",
      "19                Divorced     Exec-managerial       Unmarried   \n",
      "20      Married-civ-spouse      Prof-specialty         Husband   \n",
      "21               Separated       Other-service       Unmarried   \n",
      "22      Married-civ-spouse     Farming-fishing         Husband   \n",
      "23      Married-civ-spouse    Transport-moving         Husband   \n",
      "24                Divorced        Tech-support       Unmarried   \n",
      "25      Married-civ-spouse        Tech-support         Husband   \n",
      "26           Never-married        Craft-repair       Own-child   \n",
      "28                Divorced     Exec-managerial   Not-in-family   \n",
      "29      Married-civ-spouse        Craft-repair         Husband   \n",
      "30           Never-married     Protective-serv   Not-in-family   \n",
      "31           Never-married               Sales       Own-child   \n",
      "\n",
      "                   race      sex   capital-gain   capital-loss  \\\n",
      "0                 White     Male           2174              0   \n",
      "1                 White     Male              0              0   \n",
      "2                 White     Male              0              0   \n",
      "3                 Black     Male              0              0   \n",
      "4                 Black   Female              0              0   \n",
      "5                 White   Female              0              0   \n",
      "6                 Black   Female              0              0   \n",
      "7                 White     Male              0              0   \n",
      "8                 White   Female          14084              0   \n",
      "9                 White     Male           5178              0   \n",
      "10                Black     Male              0              0   \n",
      "11   Asian-Pac-Islander     Male              0              0   \n",
      "12                White   Female              0              0   \n",
      "13                Black     Male              0              0   \n",
      "15   Amer-Indian-Eskimo     Male              0              0   \n",
      "16                White     Male              0              0   \n",
      "17                White     Male              0              0   \n",
      "18                White     Male              0              0   \n",
      "19                White   Female              0              0   \n",
      "20                White     Male              0              0   \n",
      "21                Black   Female              0              0   \n",
      "22                Black     Male              0              0   \n",
      "23                White     Male              0           2042   \n",
      "24                White   Female              0              0   \n",
      "25                White     Male              0              0   \n",
      "26                White     Male              0              0   \n",
      "28                White     Male              0              0   \n",
      "29                White     Male              0              0   \n",
      "30                White     Male              0              0   \n",
      "31                Black     Male              0              0   \n",
      "\n",
      "     hours-per-week  native-country  income  \n",
      "0                40   United-States   <=50K  \n",
      "1                13   United-States   <=50K  \n",
      "2                40   United-States   <=50K  \n",
      "3                40   United-States   <=50K  \n",
      "4                40            Cuba   <=50K  \n",
      "5                40   United-States   <=50K  \n",
      "6                16         Jamaica   <=50K  \n",
      "7                45   United-States    >50K  \n",
      "8                50   United-States    >50K  \n",
      "9                40   United-States    >50K  \n",
      "10               80   United-States    >50K  \n",
      "11               40           India    >50K  \n",
      "12               30   United-States   <=50K  \n",
      "13               50   United-States   <=50K  \n",
      "15               45          Mexico   <=50K  \n",
      "16               35   United-States   <=50K  \n",
      "17               40   United-States   <=50K  \n",
      "18               50   United-States   <=50K  \n",
      "19               45   United-States    >50K  \n",
      "20               60   United-States    >50K  \n",
      "21               20   United-States   <=50K  \n",
      "22               40   United-States   <=50K  \n",
      "23               40   United-States   <=50K  \n",
      "24               40   United-States   <=50K  \n",
      "25               40   United-States    >50K  \n",
      "26               40   United-States   <=50K  \n",
      "28               80   United-States   <=50K  \n",
      "29               40   United-States   <=50K  \n",
      "30               52   United-States   <=50K  \n",
      "31               44   United-States   <=50K  \n"
     ]
    }
   ],
   "source": [
    "#removing missing values\n",
    "newdf=newdf.dropna()\n",
    "print(newdf[0:30])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 int64\n",
       " workclass         object\n",
       " education         object\n",
       " education-num      int64\n",
       " marital-status    object\n",
       " occupation        object\n",
       " relationship      object\n",
       " race              object\n",
       " sex               object\n",
       " capital-gain       int64\n",
       " capital-loss       int64\n",
       " hours-per-week     int64\n",
       " native-country    object\n",
       " income            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "#label the categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le= LabelEncoder()\n",
    "data=newdf[' income']\n",
    "le.fit(data.values)\n",
    "newdf[' income']=le.transform(newdf[' income'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                 int64\n",
       " workclass         object\n",
       " education         object\n",
       " education-num      int64\n",
       " marital-status    object\n",
       " occupation        object\n",
       " relationship      object\n",
       " race              object\n",
       " sex               object\n",
       " capital-gain       int64\n",
       " capital-loss       int64\n",
       " hours-per-week     int64\n",
       " native-country    object\n",
       " income             int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split and remove Y in dataset  \n",
    "Y = newdf.iloc[:, -1:].values\n",
    "newdf = newdf.drop(' income', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['age' ' workclass' ' education' ' education-num' ' marital-status'\n",
      " ' occupation' ' relationship' ' race' ' sex' ' capital-gain'\n",
      " ' capital-loss' ' hours-per-week' ' native-country']\n"
     ]
    }
   ],
   "source": [
    "print(newdf.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot the categorigal variables\n",
    "for col in newdf.columns.values:\n",
    "    if newdf[col].dtypes=='object':\n",
    "        one_hot = pd.get_dummies(newdf[col])\n",
    "        one_hot = one_hot.add_prefix(col)\n",
    "        newdf = newdf.join(one_hot)             #adding onehot encoded columns to dataframe\n",
    "        newdf = newdf.drop(col, 1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age   education-num   capital-gain   capital-loss   hours-per-week  \\\n",
      "0   39              13           2174              0               40   \n",
      "1   50              13              0              0               13   \n",
      "\n",
      "    workclass Federal-gov   workclass Local-gov   workclass Private  \\\n",
      "0                       0                     0                   0   \n",
      "1                       0                     0                   0   \n",
      "\n",
      "    workclass Self-emp-inc   workclass Self-emp-not-inc  \\\n",
      "0                        0                            0   \n",
      "1                        0                            1   \n",
      "\n",
      "              ...               native-country Portugal  \\\n",
      "0             ...                                     0   \n",
      "1             ...                                     0   \n",
      "\n",
      "    native-country Puerto-Rico   native-country Scotland  \\\n",
      "0                            0                         0   \n",
      "1                            0                         0   \n",
      "\n",
      "    native-country South   native-country Taiwan   native-country Thailand  \\\n",
      "0                      0                       0                         0   \n",
      "1                      0                       0                         0   \n",
      "\n",
      "    native-country Trinadad&Tobago   native-country United-States  \\\n",
      "0                                0                              1   \n",
      "1                                0                              1   \n",
      "\n",
      "    native-country Vietnam   native-country Yugoslavia  \n",
      "0                        0                           0  \n",
      "1                        0                           0  \n",
      "\n",
      "[2 rows x 103 columns]\n"
     ]
    }
   ],
   "source": [
    "print(newdf[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                                           int64\n",
       " education-num                                int64\n",
       " capital-gain                                 int64\n",
       " capital-loss                                 int64\n",
       " hours-per-week                               int64\n",
       " workclass Federal-gov                        uint8\n",
       " workclass Local-gov                          uint8\n",
       " workclass Private                            uint8\n",
       " workclass Self-emp-inc                       uint8\n",
       " workclass Self-emp-not-inc                   uint8\n",
       " workclass State-gov                          uint8\n",
       " workclass Without-pay                        uint8\n",
       " education 10th                               uint8\n",
       " education 11th                               uint8\n",
       " education 12th                               uint8\n",
       " education 1st-4th                            uint8\n",
       " education 5th-6th                            uint8\n",
       " education 7th-8th                            uint8\n",
       " education 9th                                uint8\n",
       " education Assoc-acdm                         uint8\n",
       " education Assoc-voc                          uint8\n",
       " education Bachelors                          uint8\n",
       " education Doctorate                          uint8\n",
       " education HS-grad                            uint8\n",
       " education Masters                            uint8\n",
       " education Preschool                          uint8\n",
       " education Prof-school                        uint8\n",
       " education Some-college                       uint8\n",
       " marital-status Divorced                      uint8\n",
       " marital-status Married-AF-spouse             uint8\n",
       "                                              ...  \n",
       " native-country Greece                        uint8\n",
       " native-country Guatemala                     uint8\n",
       " native-country Haiti                         uint8\n",
       " native-country Holand-Netherlands            uint8\n",
       " native-country Honduras                      uint8\n",
       " native-country Hong                          uint8\n",
       " native-country Hungary                       uint8\n",
       " native-country India                         uint8\n",
       " native-country Iran                          uint8\n",
       " native-country Ireland                       uint8\n",
       " native-country Italy                         uint8\n",
       " native-country Jamaica                       uint8\n",
       " native-country Japan                         uint8\n",
       " native-country Laos                          uint8\n",
       " native-country Mexico                        uint8\n",
       " native-country Nicaragua                     uint8\n",
       " native-country Outlying-US(Guam-USVI-etc)    uint8\n",
       " native-country Peru                          uint8\n",
       " native-country Philippines                   uint8\n",
       " native-country Poland                        uint8\n",
       " native-country Portugal                      uint8\n",
       " native-country Puerto-Rico                   uint8\n",
       " native-country Scotland                      uint8\n",
       " native-country South                         uint8\n",
       " native-country Taiwan                        uint8\n",
       " native-country Thailand                      uint8\n",
       " native-country Trinadad&Tobago               uint8\n",
       " native-country United-States                 uint8\n",
       " native-country Vietnam                       uint8\n",
       " native-country Yugoslavia                    uint8\n",
       "Length: 103, dtype: object"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newdf.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split dataset into its attributes and labels\n",
    "X = newdf.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  39   13 2174    0   40    0    0    0    0    0    1    0    0    0\n",
      "     0    0    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "     0    0    0    0    1    0    0    1    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    1    0    0    0    0    0\n",
      "     0    0    0    1    0    1    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    1    0    0]\n",
      " [  50   13    0    0   13    0    0    0    0    1    0    0    0    0\n",
      "     0    0    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "     0    0    1    0    0    0    0    0    0    0    1    0    0    0\n",
      "     0    0    0    0    0    0    0    1    0    0    0    0    0    0\n",
      "     0    0    0    1    0    1    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "     0    0    1    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "H:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#normalize features\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scalar= MinMaxScaler()\n",
    "scalar.fit(X)\n",
    "\n",
    "X = scalar.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.30136986 0.8        0.02174022 0.         0.39795918 0.\n",
      "  0.         0.         0.         0.         1.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         0.         0.         1.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         1.\n",
      "  0.         1.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.         0.\n",
      "  0.        ]\n",
      " [0.45205479 0.8        0.         0.         0.12244898 0.\n",
      "  0.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         1.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  1.         0.         0.         0.         0.         0.\n",
      "  0.         0.         1.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         1.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         1.\n",
      "  0.         1.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         0.         0.\n",
      "  0.         0.         0.         0.         1.         0.\n",
      "  0.        ]]\n"
     ]
    }
   ],
   "source": [
    "print(X[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define and fit the final model\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=103,kernel_initializer='uniform', activation='sigmoid'))\n",
    "model.compile(loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 19303 samples, validate on 4826 samples\n",
      "Epoch 1/1000\n",
      "19303/19303 [==============================] - 1s 47us/step - loss: 0.4823 - acc: 0.7684 - val_loss: 0.4060 - val_acc: 0.8145\n",
      "Epoch 2/1000\n",
      "19303/19303 [==============================] - 1s 33us/step - loss: 0.3955 - acc: 0.8179 - val_loss: 0.3771 - val_acc: 0.8286\n",
      "Epoch 3/1000\n",
      "19303/19303 [==============================] - 1s 34us/step - loss: 0.3769 - acc: 0.8259 - val_loss: 0.3666 - val_acc: 0.8301\n",
      "Epoch 4/1000\n",
      "19303/19303 [==============================] - 1s 34us/step - loss: 0.3686 - acc: 0.8294 - val_loss: 0.3608 - val_acc: 0.8305\n",
      "Epoch 5/1000\n",
      "19303/19303 [==============================] - 1s 38us/step - loss: 0.3635 - acc: 0.8302 - val_loss: 0.3574 - val_acc: 0.8307\n",
      "Epoch 6/1000\n",
      "19303/19303 [==============================] - 1s 35us/step - loss: 0.3601 - acc: 0.8310 - val_loss: 0.3548 - val_acc: 0.8334\n",
      "Epoch 7/1000\n",
      "19303/19303 [==============================] - 1s 35us/step - loss: 0.3575 - acc: 0.8312 - val_loss: 0.3537 - val_acc: 0.8311\n",
      "Epoch 8/1000\n",
      "19303/19303 [==============================] - 1s 35us/step - loss: 0.3553 - acc: 0.8322 - val_loss: 0.3511 - val_acc: 0.8326\n",
      "Epoch 9/1000\n",
      "19303/19303 [==============================] - 1s 36us/step - loss: 0.3536 - acc: 0.8335 - val_loss: 0.3503 - val_acc: 0.8336\n",
      "Epoch 10/1000\n",
      "19303/19303 [==============================] - 1s 35us/step - loss: 0.3521 - acc: 0.8343 - val_loss: 0.3499 - val_acc: 0.8336\n",
      "Epoch 11/1000\n",
      "19303/19303 [==============================] - 1s 36us/step - loss: 0.3507 - acc: 0.8349 - val_loss: 0.3484 - val_acc: 0.8353\n",
      "Epoch 12/1000\n",
      "19303/19303 [==============================] - 1s 42us/step - loss: 0.3494 - acc: 0.8347 - val_loss: 0.3472 - val_acc: 0.8359\n",
      "Epoch 13/1000\n",
      "19303/19303 [==============================] - 1s 38us/step - loss: 0.3485 - acc: 0.8353 - val_loss: 0.3469 - val_acc: 0.8359\n",
      "Epoch 14/1000\n",
      "19303/19303 [==============================] - 1s 35us/step - loss: 0.3474 - acc: 0.8358 - val_loss: 0.3458 - val_acc: 0.8361\n",
      "Epoch 15/1000\n",
      "19303/19303 [==============================] - 1s 36us/step - loss: 0.3465 - acc: 0.8358 - val_loss: 0.3452 - val_acc: 0.8365\n",
      "Epoch 16/1000\n",
      "19303/19303 [==============================] - 1s 42us/step - loss: 0.3456 - acc: 0.8371 - val_loss: 0.3443 - val_acc: 0.8369\n",
      "Epoch 17/1000\n",
      "19303/19303 [==============================] - 1s 49us/step - loss: 0.3449 - acc: 0.8372 - val_loss: 0.3445 - val_acc: 0.8363\n",
      "Epoch 18/1000\n",
      "19303/19303 [==============================] - 1s 47us/step - loss: 0.3442 - acc: 0.8381 - val_loss: 0.3440 - val_acc: 0.8373\n",
      "Epoch 19/1000\n",
      "19303/19303 [==============================] - 1s 34us/step - loss: 0.3435 - acc: 0.8382 - val_loss: 0.3430 - val_acc: 0.8369\n",
      "Epoch 20/1000\n",
      "19303/19303 [==============================] - 1s 40us/step - loss: 0.3430 - acc: 0.8386 - val_loss: 0.3425 - val_acc: 0.8365\n",
      "Epoch 21/1000\n",
      "19303/19303 [==============================] - 1s 41us/step - loss: 0.3423 - acc: 0.8381 - val_loss: 0.3421 - val_acc: 0.8373\n",
      "Epoch 22/1000\n",
      "19303/19303 [==============================] - 1s 30us/step - loss: 0.3418 - acc: 0.8385 - val_loss: 0.3427 - val_acc: 0.8367\n",
      "Epoch 23/1000\n",
      "19303/19303 [==============================] - 1s 30us/step - loss: 0.3413 - acc: 0.8395 - val_loss: 0.3426 - val_acc: 0.8361\n",
      "Epoch 24/1000\n",
      "19303/19303 [==============================] - 1s 35us/step - loss: 0.3408 - acc: 0.8401 - val_loss: 0.3410 - val_acc: 0.8400\n",
      "Epoch 25/1000\n",
      "19303/19303 [==============================] - 1s 43us/step - loss: 0.3404 - acc: 0.8405 - val_loss: 0.3409 - val_acc: 0.8375\n",
      "Epoch 26/1000\n",
      "19303/19303 [==============================] - 1s 43us/step - loss: 0.3400 - acc: 0.8393 - val_loss: 0.3405 - val_acc: 0.8392\n",
      "Epoch 27/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3396 - acc: 0.8405 - val_loss: 0.3408 - val_acc: 0.8365\n",
      "Epoch 28/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3393 - acc: 0.8416 - val_loss: 0.3403 - val_acc: 0.8386\n",
      "Epoch 29/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3389 - acc: 0.8417 - val_loss: 0.3398 - val_acc: 0.8392\n",
      "Epoch 30/1000\n",
      "19303/19303 [==============================] - 1s 31us/step - loss: 0.3385 - acc: 0.8416 - val_loss: 0.3398 - val_acc: 0.8384\n",
      "Epoch 31/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3381 - acc: 0.8416 - val_loss: 0.3393 - val_acc: 0.8404\n",
      "Epoch 32/1000\n",
      "19303/19303 [==============================] - 1s 30us/step - loss: 0.3378 - acc: 0.8424 - val_loss: 0.3393 - val_acc: 0.8384\n",
      "Epoch 33/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3374 - acc: 0.8420 - val_loss: 0.3393 - val_acc: 0.8378\n",
      "Epoch 34/1000\n",
      "19303/19303 [==============================] - 1s 34us/step - loss: 0.3372 - acc: 0.8432 - val_loss: 0.3390 - val_acc: 0.8378\n",
      "Epoch 35/1000\n",
      "19303/19303 [==============================] - 1s 31us/step - loss: 0.3369 - acc: 0.8424 - val_loss: 0.3384 - val_acc: 0.8402\n",
      "Epoch 36/1000\n",
      "19303/19303 [==============================] - 1s 30us/step - loss: 0.3366 - acc: 0.8432 - val_loss: 0.3383 - val_acc: 0.8402\n",
      "Epoch 37/1000\n",
      "19303/19303 [==============================] - 1s 30us/step - loss: 0.3363 - acc: 0.8438 - val_loss: 0.3380 - val_acc: 0.8407\n",
      "Epoch 38/1000\n",
      "19303/19303 [==============================] - 1s 30us/step - loss: 0.3361 - acc: 0.8432 - val_loss: 0.3382 - val_acc: 0.8392\n",
      "Epoch 39/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3358 - acc: 0.8434 - val_loss: 0.3379 - val_acc: 0.8390\n",
      "Epoch 40/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3355 - acc: 0.8446 - val_loss: 0.3376 - val_acc: 0.8407\n",
      "Epoch 41/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3354 - acc: 0.8434 - val_loss: 0.3379 - val_acc: 0.8392\n",
      "Epoch 42/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3351 - acc: 0.8441 - val_loss: 0.3378 - val_acc: 0.8394\n",
      "Epoch 43/1000\n",
      "19303/19303 [==============================] - 1s 30us/step - loss: 0.3349 - acc: 0.8443 - val_loss: 0.3371 - val_acc: 0.8421\n",
      "Epoch 44/1000\n",
      "19303/19303 [==============================] - 1s 32us/step - loss: 0.3346 - acc: 0.8450 - val_loss: 0.3370 - val_acc: 0.8415\n",
      "Epoch 45/1000\n",
      "19303/19303 [==============================] - 1s 30us/step - loss: 0.3345 - acc: 0.8444 - val_loss: 0.3371 - val_acc: 0.8415\n",
      "Epoch 46/1000\n",
      "19303/19303 [==============================] - 1s 37us/step - loss: 0.3344 - acc: 0.8439 - val_loss: 0.3368 - val_acc: 0.8429\n",
      "Epoch 47/1000\n",
      "19303/19303 [==============================] - 1s 38us/step - loss: 0.3341 - acc: 0.8450 - val_loss: 0.3368 - val_acc: 0.8429\n",
      "Epoch 48/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3340 - acc: 0.8457 - val_loss: 0.3367 - val_acc: 0.8427\n",
      "Epoch 49/1000\n",
      "19303/19303 [==============================] - 1s 28us/step - loss: 0.3338 - acc: 0.8452 - val_loss: 0.3366 - val_acc: 0.8427\n",
      "Epoch 50/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3337 - acc: 0.8458 - val_loss: 0.3365 - val_acc: 0.8427\n",
      "Epoch 51/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3336 - acc: 0.8455 - val_loss: 0.3368 - val_acc: 0.8415\n",
      "Epoch 52/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3335 - acc: 0.8455 - val_loss: 0.3363 - val_acc: 0.8431\n",
      "Epoch 53/1000\n",
      "19303/19303 [==============================] - 1s 28us/step - loss: 0.3335 - acc: 0.8448 - val_loss: 0.3362 - val_acc: 0.8440\n",
      "Epoch 54/1000\n",
      "19303/19303 [==============================] - 1s 28us/step - loss: 0.3333 - acc: 0.8459 - val_loss: 0.3361 - val_acc: 0.8442\n",
      "Epoch 55/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3332 - acc: 0.8460 - val_loss: 0.3363 - val_acc: 0.8427\n",
      "Epoch 56/1000\n",
      "19303/19303 [==============================] - 1s 29us/step - loss: 0.3329 - acc: 0.8458 - val_loss: 0.3361 - val_acc: 0.8431\n",
      "Epoch 57/1000\n",
      "19303/19303 [==============================] - 1s 28us/step - loss: 0.3329 - acc: 0.8457 - val_loss: 0.3363 - val_acc: 0.8421\n"
     ]
    }
   ],
   "source": [
    "#fit the model\n",
    "from keras.callbacks import EarlyStopping \n",
    "early_stopping = EarlyStopping(monitor='val_loss',min_delta=0,patience=3,verbose=0,mode='auto')\n",
    "weights=model.get_weights()\n",
    "history=model.fit(X_train,Y_train,validation_split=0.2,epochs=1000,callbacks = [early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot history of loss and validation loss against epoch\n",
    "plt.plot(np.array(history.history['loss']), label=\"train\")\n",
    "plt.plot(np.array(history.history['val_loss']), label=\"validation\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Training\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.34944469418352603\n",
      "Test accuracy: 0.8395491464110763\n"
     ]
    }
   ],
   "source": [
    "# Test the trained model on the test set\n",
    "score = model.evaluate(X_test, Y_test, verbose=0) \n",
    "print('Test loss:', score[0]) \n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4114  346]\n",
      " [ 622  951]]\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.87      0.92      0.89      4460\n",
      "          1       0.73      0.60      0.66      1573\n",
      "\n",
      "avg / total       0.83      0.84      0.83      6033\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predict\n",
    "y_pred = model.predict_classes(X_test)\n",
    "\n",
    "#Evaluating the Algorithm\n",
    "from sklearn.metrics import classification_report, confusion_matrix  \n",
    "print(confusion_matrix(Y_test, y_pred))  \n",
    "print(classification_report(Y_test, y_pred)) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
